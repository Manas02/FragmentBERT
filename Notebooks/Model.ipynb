{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Models are Fragment Based Drug Designers \n",
    "## Author : Manas Mahale <<manas.mahale@bcp.edu.in>> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizerFast, LineByLineTextDataset, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig , BertForMaskedLM, TrainingArguments, Trainer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"smiles/canonical_train_scaffold.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "vocab_size = tokenizer.get_vocab_size() # can also try tokenizer.get_vocab_size()\n",
    "model_path = 'smiles-bert/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.enable_truncation(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('smiles-bert/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"./smiles-bert/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.unk_token = \"[UNK]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.sep_token = \"[SEP]\"\n",
    "tokenizer.cls_token = \"[CLS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 ms, sys: 2.54 ms, total: 7.66 ms\n",
      "Wall time: 3.31 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./smiles/canonical_train_scaffold.txt\",\n",
    "    block_size=128,\n",
    ")\n",
    "\n",
    "test_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./smiles/canonical_test.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the model with the config\n",
    "model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
    "model = BertForMaskedLM(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,          # output directory to where save model checkpoint\n",
    "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
    "    overwrite_output_dir=True,      \n",
    "    num_train_epochs=50,            # number of training epochs, feel free to tweak\n",
    "    per_device_train_batch_size=10, # the training batch size, put it as high as your GPU memory fits\n",
    "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
    "    per_device_eval_batch_size=64,  # evaluation batch size\n",
    "    logging_steps=1,             # evaluate, log and save model checkpoints every 1000 step\n",
    "    save_steps=1,\n",
    "    load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
    "    save_total_limit=1,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the trainer and pass everything to it\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 80\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 11:47, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.904400</td>\n",
       "      <td>4.416520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.276200</td>\n",
       "      <td>4.019030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.024500</td>\n",
       "      <td>3.477090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.046600</td>\n",
       "      <td>3.460977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.847800</td>\n",
       "      <td>3.443731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.965300</td>\n",
       "      <td>3.445435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.597100</td>\n",
       "      <td>3.447366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.138600</td>\n",
       "      <td>3.422358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.413600</td>\n",
       "      <td>3.114475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.683300</td>\n",
       "      <td>3.525752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.413000</td>\n",
       "      <td>3.241367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.787300</td>\n",
       "      <td>3.432138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.272800</td>\n",
       "      <td>3.613029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.471700</td>\n",
       "      <td>3.195936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.546100</td>\n",
       "      <td>3.021057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.033000</td>\n",
       "      <td>2.777623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.993000</td>\n",
       "      <td>2.946029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.041500</td>\n",
       "      <td>2.632359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.198800</td>\n",
       "      <td>2.686482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.915700</td>\n",
       "      <td>2.749996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.177800</td>\n",
       "      <td>2.010766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.873600</td>\n",
       "      <td>3.120267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>4.324100</td>\n",
       "      <td>3.005702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>4.225600</td>\n",
       "      <td>3.043159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.674900</td>\n",
       "      <td>2.861506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>4.321500</td>\n",
       "      <td>2.948639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.099100</td>\n",
       "      <td>2.765142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.877700</td>\n",
       "      <td>2.714753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>4.009100</td>\n",
       "      <td>2.611681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.883700</td>\n",
       "      <td>2.776485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.904500</td>\n",
       "      <td>2.997486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>4.141700</td>\n",
       "      <td>2.354631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.792300</td>\n",
       "      <td>1.544468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.736500</td>\n",
       "      <td>2.492594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.980400</td>\n",
       "      <td>2.178414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.707600</td>\n",
       "      <td>2.813401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.692300</td>\n",
       "      <td>3.133864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.814100</td>\n",
       "      <td>2.963786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.815900</td>\n",
       "      <td>2.468316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.404100</td>\n",
       "      <td>2.002021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.531000</td>\n",
       "      <td>2.813099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.615900</td>\n",
       "      <td>2.555912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.797000</td>\n",
       "      <td>2.627553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.473900</td>\n",
       "      <td>2.308128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.271600</td>\n",
       "      <td>2.323277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.776900</td>\n",
       "      <td>1.566630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.426700</td>\n",
       "      <td>2.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.484900</td>\n",
       "      <td>2.273549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.603500</td>\n",
       "      <td>2.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.643400</td>\n",
       "      <td>2.650374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-1\n",
      "Configuration saved in smiles-bert/checkpoint-1/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-1/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-2\n",
      "Configuration saved in smiles-bert/checkpoint-2/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-2/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-1] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-3\n",
      "Configuration saved in smiles-bert/checkpoint-3/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-3/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-2] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-4\n",
      "Configuration saved in smiles-bert/checkpoint-4/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-4/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-3] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-5\n",
      "Configuration saved in smiles-bert/checkpoint-5/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-5/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-4] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-6\n",
      "Configuration saved in smiles-bert/checkpoint-6/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-6/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-7\n",
      "Configuration saved in smiles-bert/checkpoint-7/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-7/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-6] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-8\n",
      "Configuration saved in smiles-bert/checkpoint-8/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-8/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-5] due to args.save_total_limit\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-7] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-9\n",
      "Configuration saved in smiles-bert/checkpoint-9/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-9/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-8] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-10\n",
      "Configuration saved in smiles-bert/checkpoint-10/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-11\n",
      "Configuration saved in smiles-bert/checkpoint-11/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-11/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-12\n",
      "Configuration saved in smiles-bert/checkpoint-12/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-11] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-13\n",
      "Configuration saved in smiles-bert/checkpoint-13/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-13/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-12] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-14\n",
      "Configuration saved in smiles-bert/checkpoint-14/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-14/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-13] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-15\n",
      "Configuration saved in smiles-bert/checkpoint-15/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-15/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-9] due to args.save_total_limit\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-14] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-16\n",
      "Configuration saved in smiles-bert/checkpoint-16/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-16/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-15] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-17\n",
      "Configuration saved in smiles-bert/checkpoint-17/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-17/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-18\n",
      "Configuration saved in smiles-bert/checkpoint-18/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-18/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-16] due to args.save_total_limit\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-17] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-19\n",
      "Configuration saved in smiles-bert/checkpoint-19/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-19/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-20\n",
      "Configuration saved in smiles-bert/checkpoint-20/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-20/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-19] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-21\n",
      "Configuration saved in smiles-bert/checkpoint-21/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-21/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-18] due to args.save_total_limit\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-20] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-22\n",
      "Configuration saved in smiles-bert/checkpoint-22/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-22/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-23\n",
      "Configuration saved in smiles-bert/checkpoint-23/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-23/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-22] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-24\n",
      "Configuration saved in smiles-bert/checkpoint-24/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-24/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-23] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-25\n",
      "Configuration saved in smiles-bert/checkpoint-25/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-25/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-24] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in smiles-bert/checkpoint-26/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-26/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-25] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-27\n",
      "Configuration saved in smiles-bert/checkpoint-27/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-27/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-26] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-28\n",
      "Configuration saved in smiles-bert/checkpoint-28/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-28/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-27] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-29\n",
      "Configuration saved in smiles-bert/checkpoint-29/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-29/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-28] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-30\n",
      "Configuration saved in smiles-bert/checkpoint-30/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-30/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-29] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-31\n",
      "Configuration saved in smiles-bert/checkpoint-31/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-31/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-30] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-32\n",
      "Configuration saved in smiles-bert/checkpoint-32/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-31] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-33\n",
      "Configuration saved in smiles-bert/checkpoint-33/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-33/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-21] due to args.save_total_limit\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-34\n",
      "Configuration saved in smiles-bert/checkpoint-34/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-34/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-35\n",
      "Configuration saved in smiles-bert/checkpoint-35/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-35/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-34] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-36\n",
      "Configuration saved in smiles-bert/checkpoint-36/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-36/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-35] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-37\n",
      "Configuration saved in smiles-bert/checkpoint-37/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-37/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-36] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-38\n",
      "Configuration saved in smiles-bert/checkpoint-38/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-38/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-37] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-39\n",
      "Configuration saved in smiles-bert/checkpoint-39/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-39/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-38] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-40\n",
      "Configuration saved in smiles-bert/checkpoint-40/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-40/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-39] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-41\n",
      "Configuration saved in smiles-bert/checkpoint-41/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-41/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-40] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-42\n",
      "Configuration saved in smiles-bert/checkpoint-42/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-42/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-41] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-43\n",
      "Configuration saved in smiles-bert/checkpoint-43/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-43/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-42] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-44\n",
      "Configuration saved in smiles-bert/checkpoint-44/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-44/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-43] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-45\n",
      "Configuration saved in smiles-bert/checkpoint-45/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-45/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-44] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-46\n",
      "Configuration saved in smiles-bert/checkpoint-46/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-46/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-45] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-47\n",
      "Configuration saved in smiles-bert/checkpoint-47/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-47/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-46] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-48\n",
      "Configuration saved in smiles-bert/checkpoint-48/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-48/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-47] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-49\n",
      "Configuration saved in smiles-bert/checkpoint-49/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-49/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-48] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to smiles-bert/checkpoint-50\n",
      "Configuration saved in smiles-bert/checkpoint-50/config.json\n",
      "Model weights saved in smiles-bert/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [smiles-bert/checkpoint-49] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from smiles-bert/checkpoint-33 (score: 1.544467806816101).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=4.1330337762832645, metrics={'train_runtime': 718.4513, 'train_samples_per_second': 6.959, 'train_steps_per_second': 0.07, 'total_flos': 23304882566700.0, 'train_loss': 4.1330337762832645, 'epoch': 49.8})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertForMaskedLM.from_pretrained(os.path.join(model_path, \"checkpoint-10000\"))\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.18074874579906464, 'token': 6, 'token_str': 'CC=O', 'sequence': 'Clc1ccccc1 CC=O S c1nnco1 CCC N'}\n",
      "{'score': 0.13201986253261566, 'token': 11, 'token_str': 'CCC', 'sequence': 'Clc1ccccc1 CCC S c1nnco1 CCC N'}\n",
      "{'score': 0.06030702218413353, 'token': 7, 'token_str': 'C=O', 'sequence': 'Clc1ccccc1 C=O S c1nnco1 CCC N'}\n",
      "{'score': 0.05809904262423515, 'token': 15, 'token_str': 'CCC=O', 'sequence': 'Clc1ccccc1 CCC=O S c1nnco1 CCC N'}\n",
      "{'score': 0.03378932178020477, 'token': 9, 'token_str': 'c1ccccc1', 'sequence': 'Clc1ccccc1 c1ccccc1 S c1nnco1 CCC N'}\n"
     ]
    }
   ],
   "source": [
    "# perform predictions\n",
    "example = \"Clc1ccccc1 [MASK] S c1nnco1 CCC N\"\n",
    "for prediction in fill_mask(example):\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
